{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIaA1_nmv0fs"
   },
   "source": [
    "## Домашнее задание №9\n",
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UvkXpjtPv0fu",
    "ExecuteTime": {
     "end_time": "2024-11-15T20:09:37.860964Z",
     "start_time": "2024-11-15T20:09:37.854855Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kRH41cMov0fv",
    "ExecuteTime": {
     "end_time": "2024-11-15T20:09:37.908920Z",
     "start_time": "2024-11-15T20:09:37.903683Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"{} device is available\".format(device))\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu device is available\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "it4MDjxnv0fw",
    "ExecuteTime": {
     "end_time": "2024-11-15T20:09:38.189153Z",
     "start_time": "2024-11-15T20:09:37.920962Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "\n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "\n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'onegin.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# do not change the code in the block below\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# __________start of block__________\u001B[39;00m\n\u001B[0;32m      3\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43monegin.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m iofile:\n\u001B[0;32m      6\u001B[0m     text \u001B[38;5;241m=\u001B[39m iofile\u001B[38;5;241m.\u001B[39mreadlines()\n\u001B[0;32m      8\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([x\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m text])\n",
      "File \u001B[1;32mC:\\WORKS\\PythonCode\\ML\\poetry\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'onegin.txt'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6cmyE29fv0fw"
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + [\"<sos>\"]\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8LLSQNSv0fx"
   },
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wPXIXg09v0fx",
    "ExecuteTime": {
     "end_time": "2024-11-15T20:09:38.193193Z",
     "start_time": "2024-11-15T20:09:38.192159Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx[\"<sos>\"]\n",
    "\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size * seq_length - 1)\n",
    "    data = np.array(\n",
    "        text_encoded[start_index : start_index + batch_size * seq_length]\n",
    "    ).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgaxh51tv0fx"
   },
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7_oAuHqiv0fx",
    "outputId": "ad177cd0-067c-4ce0-ee25-47aa9c0e7be2",
    "ExecuteTime": {
     "end_time": "2024-11-15T20:09:38.195159Z",
     "start_time": "2024-11-15T20:09:38.194160Z"
    }
   },
   "source": [
    "next(generate_chunk())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMZ-jleOv0fy"
   },
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-FPjEvUpv0fy"
   },
   "source": [
    "# your beautiful experiments here\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, num_tokens, hidden_size, num_layers):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_tokens, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_tokens)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "\n",
    "# Гиперпараметры\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Инициализация модели\n",
    "model = CharRNN(num_tokens, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in generate_chunk():\n",
    "        inputs = torch.tensor(data[:, :-1]).to(device)\n",
    "        targets = torch.tensor(data[:, 1:]).to(device)\n",
    "\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/batch_size}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9nrInSyv0fy"
   },
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VqWs5NOfv0fy",
    "outputId": "c656b66a-2194-41fc-d182-2e2657622e1a"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGw0kfdZv0fy"
   },
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sJ0FtPtkv0fy"
   },
   "source": [
    "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
    "    if seed_phrase is not None:\n",
    "        x_sequence = [token_to_idx[\"<sos>\"]] + [token_to_idx[token] for token in seed_phrase]\n",
    "    else:\n",
    "        x_sequence = [token_to_idx[\"<sos>\"]]\n",
    "\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
    "    hidden = char_rnn.init_hidden(1)\n",
    "\n",
    "    for _ in range(max_length - len(x_sequence[0])):\n",
    "        output, hidden = char_rnn(x_sequence[:, -1:], hidden)\n",
    "        output = output.view(-1).div(temperature).exp()\n",
    "        output = output / output.sum()\n",
    "        next_token = torch.multinomial(output, 1)\n",
    "        x_sequence = torch.cat((x_sequence, next_token.unsqueeze(0)), dim=1)\n",
    "\n",
    "    return \"\".join([tokens[ix] for ix in x_sequence.cpu().data.numpy()[0]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rm40c5Jv0fy"
   },
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nQ_bPNF4v0fy",
    "outputId": "e6fa5cac-004d-4aef-fd04-8b83a0aacb6f"
   },
   "source": [
    "print(\n",
    "    generate_sample(\n",
    "        model, \" мой дядя самых честных правил\", max_length=500, temperature=0.8\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cElzSEwv0f0"
   },
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FtwgQ3rZv0f0"
   },
   "source": [
    "seed_phrase = \" мой дядя самых честных правил\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ry8AmNaYv0f0"
   },
   "source": [
    "# generated_phrases = # your code here\n",
    "generated_phrases = \" мой дядя самых честных правил\"\n",
    "\n",
    "generated_phrases = [\n",
    "    generate_sample(model, generated_phrases, max_length=500, temperature=0.8).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]\n",
    "\n",
    "# For example:\n",
    "\n",
    "# generated_phrases = [\n",
    "#     generate_sample(\n",
    "#         model,\n",
    "#         ' мой дядя самых честных правил',\n",
    "#         max_length=500,\n",
    "#         temperature=1.\n",
    "#     ).replace('<sos>', '')\n",
    "#     for _ in range(10)\n",
    "# ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9U3pAAOqv0f0"
   },
   "source": [
    "output = {key: ','.join([str(x) for x in list(data.item()[key])]) for key in 'train', 'test'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1VI-ISdev0f0"
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "if \"generated_phrases\" not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all(\n",
    "        [x in set(tokens) for x in set(list(phrase))]\n",
    "    ), \"Unknown tokens detected, check your submission!\"\n",
    "\n",
    "\n",
    "submission_dict = {\"token_to_idx\": token_to_idx, \"generated_phrases\": generated_phrases}\n",
    "\n",
    "np.save(\"submission_dict_hw09.npy\", submission_dict, allow_pickle=True)\n",
    "print(\"File saved to `submission_dict_hw09.npy`\")\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpiWso0v0f0"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
